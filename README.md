Это мое тестовое задание для ВК на позицию стажера "ML Developer"


# Подходы

Вообще, я нашел несколько подходов.


1) [Статья](https://assets.amazon.science/1a/f8/ca48a6bf4c50a7611f8baa8be1c8/intro-and-recap-detection-for-movies-and-tv-series.pdf)


Тут авторы выделяют признаки из фреймов видео и мел-спектрограмм аудио, затем объеденяют их и отдают в B-LSTM-CRF. Обучают на лоссе для crf.


2) [Статья](https://arxiv.org/pdf/2504.09738)

Тут просто берут фреймы видео, отдают в CLIP, затем с позиционным кодированием отдают в multihead attention. Обучают просто классификацию.


# Решение

Я хочу учитывать и видео, и аудио. Поэтому буду ориентироваться на первый подход. Для выделения признаков из изображений подойдет любая сеть от ResNet до DINO. 
Для аудио выбор также широк Wav2Vec, Whisper и тд. Но можно взять просто сверточную сеть. Для работы на выделенных признаках также можно взять разные модели: LSTM, B-LSTM, модель с вниманием и тд. 
А crf на конце поможет с предсказанием последовательностей из меток. 

# Что написал

Я успел написать предобработку данных: 
1) Будем брать по 3 минуты, иначе данные никуда не влазят
2) Из 1 секунды видео будем брать 1 кадр, а аудио преобразовывать в mel спектрограмму.
3) Из времени начала и конца заставки сделаем бинарный вектор: на какой секунде идет заставка
4) Полученные тензоры и таргет сохраняем на диск. Потому что все данные никуда не поместятся, а обрабатывть налету долго.


Также я начал делать модель, но не успел все сделать.
